{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data:image/png;base64,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\" alt=\"DSW LOGO\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eiKSLYG8XvO"
   },
   "source": [
    "# Challenge : predict conversions üèÜüèÜ\n",
    "\n",
    "This is the template that shows the different steps of the challenge. In this notebook, all the training/predictions steps are implemented for a very basic model (logistic regression with only one variable). Please use this template and feel free to change the preprocessing/training steps to get the model with the best f1-score ! May the force be with you üß®üß®  \n",
    "\n",
    "**For a detailed description of this project, please refer to *02-Conversion_rate_challenge.ipynb*.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGhdl7Bt2xZd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, ConfusionMatrixDisplay, RocCurveDisplay, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LHgro65rxKF7"
   },
   "source": [
    "# Read file with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W1AU8AH8u0qd",
    "outputId": "00698a97-027b-493b-a2e4-33fdcc295abb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set with labels (our train+test) : (284580, 6)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('conversion_data_train.csv')\n",
    "print('Set with labels (our train+test) :', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Seo</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  age  new_user  source  total_pages_visited  converted\n",
       "0    China   22         1  Direct                    2          0\n",
       "1       UK   21         1     Ads                    3          0\n",
       "2  Germany   20         0     Seo                   14          1\n",
       "3       US   23         1     Seo                    3          0\n",
       "4       US   28         1  Direct                    3          0"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0XwjKBc63B1n"
   },
   "source": [
    "# Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NM0feCss5sLZ"
   },
   "outputs": [],
   "source": [
    "# The dataset is quite big : you must create a sample of the dataset before making any visualizations !\n",
    "data_sample = data.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ],
         "type": "heatmap",
         "x": [
          "age",
          "new_user",
          "total_pages_visited",
          "converted"
         ],
         "y": [
          "age",
          "new_user",
          "total_pages_visited",
          "converted"
         ],
         "z": [
          [
           1,
           0.0019909061776376955,
           -0.04919909236192942,
           -0.08665172657079664
          ],
          [
           0.0019909061776376955,
           1,
           -0.0759078155356218,
           -0.1473706694196084
          ],
          [
           -0.04919909236192942,
           -0.0759078155356218,
           1,
           0.5425922876118061
          ],
          [
           -0.08665172657079664,
           -0.1473706694196084,
           0.5425922876118061,
           1
          ]
         ],
         "zmid": 0
        }
       ],
       "layout": {
        "height": 900,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Correlation Heatmap"
        },
        "width": 1200
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = data_sample.corr()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Heatmap(\n",
    "    z = corr,\n",
    "    x = corr.columns.values,\n",
    "    y = corr.columns.values,\n",
    "    colorscale=px.colors.diverging.RdBu,\n",
    "    zmid=0\n",
    "))\n",
    "\n",
    "fig.update_layout(width=1200, height=900, title='Correlation Heatmap')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.967742\n",
       "1    0.032258\n",
       "Name: converted, dtype: float64"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['converted'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 22807 to 40375\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   country              10000 non-null  object\n",
      " 1   age                  10000 non-null  int64 \n",
      " 2   new_user             10000 non-null  int64 \n",
      " 3   source               10000 non-null  object\n",
      " 4   total_pages_visited  10000 non-null  int64 \n",
      " 5   converted            10000 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 546.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data_sample.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only strongly correlated feature with `converted` is `total_pages_visited`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70MwsoCS3QD5"
   },
   "source": [
    "# Make your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dPh1qPTf3wZU"
   },
   "source": [
    "## Choose variables to use in the model, and create train and test sets\n",
    "**From the EDA, we know that the most useful feature is total_pages_visited. Let's create a baseline model by using at first only this feature : in the next cells, we'll make preprocessings and train a simple (univariate) logistic regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjEHMGoY3kMB"
   },
   "outputs": [],
   "source": [
    "features_list = ['total_pages_visited']\n",
    "numeric_indices = [0]\n",
    "categorical_indices = []\n",
    "target_variable = 'converted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "SV5E9KMs4xcq",
    "outputId": "9d1ed76e-e82e-45e7-f3e5-6d47962caa5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanatory variables :  Index(['total_pages_visited'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data.loc[:, features_list]\n",
    "Y = data.loc[:, target_variable]\n",
    "\n",
    "print('Explanatory variables : ', X.columns)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "W8K5DQEvvQgl",
    "outputId": "d280ebc9-4d4b-4723-b9fe-32513f898abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "vVu0eXQD4xVc",
    "outputId": "83a5f553-f50d-44dc-d12a-6cb21e74e4d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert pandas DataFrames to numpy arrays...\n",
      "...Done\n",
      "[[4]\n",
      " [8]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[7]\n",
      " [5]]\n",
      "\n",
      "[0 0 0 0 0]\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.values\n",
    "Y_test = Y_test.values\n",
    "print(\"...Done\")\n",
    "\n",
    "print(X_train[0:5,:])\n",
    "print(X_test[0:2,:])\n",
    "print()\n",
    "print(Y_train[0:5])\n",
    "print(Y_test[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7b_aU7ij7K3Q"
   },
   "source": [
    "## Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "_9bEZ5bn7I5Z",
    "outputId": "ad5c8f97-2d25-4827-f1ee-43c665a97fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done\n",
      "[[-0.26070136]\n",
      " [ 0.93728655]\n",
      " [-0.85969532]\n",
      " [-0.56019834]\n",
      " [-0.26070136]]\n"
     ]
    }
   ],
   "source": [
    "# Put here all the preprocessings\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "featureencoder = StandardScaler()\n",
    "X_train = featureencoder.fit_transform(X_train)\n",
    "print(\"...Done\")\n",
    "print(X_train[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "1qhidLbq7o-5",
    "outputId": "6bfb746c-1ff4-41c9-b0d6-a98fd09a444d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model...\n",
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Train model...\")\n",
    "classifier = LogisticRegression() # \n",
    "classifier.fit(X_train, Y_train)\n",
    "print(\"...Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "Au2TK_vw7rD-",
    "outputId": "702789a8-4631-4c29-f297-e4b2901f3195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = classifier.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7TY_v9uH_CE7"
   },
   "source": [
    "## Test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "ngOSdG6-_Cvb",
    "outputId": "1e19e8ee-222f-413b-9bc0-e9f41dcca1c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done\n",
      "[[ 0.63778957]\n",
      " [ 0.03879562]\n",
      " [-0.26070136]\n",
      " [-0.26070136]\n",
      " [ 0.63778957]]\n"
     ]
    }
   ],
   "source": [
    "# Use X_test, and the same preprocessings as in training pipeline, \n",
    "# but call \"transform()\" instead of \"fit_transform\" methods (see example below)\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "X_test = featureencoder.transform(X_test)\n",
    "print(\"...Done\")\n",
    "print(X_test[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "QS1XrzzE_jQI",
    "outputId": "866a96d2-4180-4bd1-ce54-ba052e75d485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = classifier.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zxJCTlz0_2it"
   },
   "source": [
    "## Performance assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6x7p1nyr_3UV",
    "outputId": "8e5b91ba-ca06-4486-d808-37a6aaaa8cf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score on train set :  0.6938517686692869\n",
      "f1-score on test set :  0.7060240963855423\n"
     ]
    }
   ],
   "source": [
    "# WARNING : Use the same score as the one that will be used by Kaggle !\n",
    "# Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "print(\"f1-score on train set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "KhDTCeBy__JK",
    "outputId": "72c82d66-d765-437e-e9ef-4ccc80e7183f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on train set : \n",
      "[[246817   1082]\n",
      " [  3280   4943]]\n",
      "\n",
      "Confusion matrix on test set : \n",
      "[[27384   117]\n",
      " [  371   586]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can also check more performance metrics to better understand what your model is doing\n",
    "print(\"Confusion matrix on train set : \")\n",
    "print(confusion_matrix(Y_train, Y_train_pred))\n",
    "print()\n",
    "print(\"Confusion matrix on test set : \")\n",
    "print(confusion_matrix(Y_test, Y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our baseline model reaches a f1-score of almost 70%. Now, feel free to refine your model and try to beat this score ! üöÄüöÄ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 22807 to 40375\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   country              10000 non-null  object\n",
      " 1   age                  10000 non-null  int64 \n",
      " 2   new_user             10000 non-null  int64 \n",
      " 3   source               10000 non-null  object\n",
      " 4   total_pages_visited  10000 non-null  int64 \n",
      " 5   converted            10000 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 546.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "cols = ['country', 'age', 'new_user', 'source', 'total_pages_visited']\n",
    "X = data[cols]\n",
    "y = data['converted']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert pandas DataFrames to numpy arrays...\n",
      "...Done\n",
      "[['China' 23 1 'Seo' 4]\n",
      " ['US' 17 1 'Ads' 4]\n",
      " ['US' 23 1 'Ads' 4]\n",
      " ['US' 25 0 'Seo' 8]\n",
      " ['US' 31 1 'Seo' 5]]\n",
      "[['US' 24 1 'Seo' 6]\n",
      " ['US' 26 1 'Seo' 7]]\n",
      "\n",
      "[0 0 0 0 0]\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "print(\"...Done\")\n",
    "\n",
    "print(X_train[0:5,:])\n",
    "print(X_test[0:2,:])\n",
    "print()\n",
    "print(y_train[0:5])\n",
    "print(y_test[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "numeric_features = [1, 2, 4]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = [0, 3]\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('encoder', OneHotEncoder(drop=\"first\"))\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213435, 8)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifiers\n",
    "tree = DecisionTreeClassifier(max_depth=5)\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "logreg = LogisticRegression()\n",
    "rfc = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for the KNN model on train set: 0.7798613299716356\n",
      "F1 Score for the KNN model on test set: 0.7364414843006661\n",
      "\n",
      "F1 Score for the Decision Tree model on train set: 0.742246335735687\n",
      "F1 Score for the Decision Tree model on test set: 0.7466601894583434\n",
      "\n",
      "F1 Score for the Naive Bayes model on train set: 0.6891154225583689\n",
      "F1 Score for the Naive Bayes model on test set: 0.6933386677335468\n",
      "\n",
      "F1 Score for the Logistic Regression model on train set: 0.763873250764034\n",
      "F1 Score for the Logistic Regression model on test set: 0.7619970916141542\n",
      "\n",
      "F1 Score for the Random Forest model on train set: 0.8082991479962133\n",
      "F1 Score for the Random Forest model on test set: 0.7328605200945627\n"
     ]
    }
   ],
   "source": [
    "# Quick model review\n",
    "knn.fit(X_train, y_train)\n",
    "y_train_knn = knn.predict(X_train)\n",
    "y_test_knn = knn.predict(X_test)\n",
    "\n",
    "print(f\"F1 Score for the KNN model on train set: {f1_score(y_train, y_train_knn)}\")\n",
    "print(f\"F1 Score for the KNN model on test set: {f1_score(y_test, y_test_knn)}\\n\")\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "y_train_tree = tree.predict(X_train)\n",
    "y_test_tree = tree.predict(X_test)\n",
    "\n",
    "print(f\"F1 Score for the Decision Tree model on train set: {f1_score(y_train, y_train_tree)}\")\n",
    "print(f\"F1 Score for the Decision Tree model on test set: {f1_score(y_test, y_test_tree)}\\n\")\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "y_train_nb = nb.predict(X_train)\n",
    "y_test_nb = nb.predict(X_test)\n",
    "\n",
    "print(f\"F1 Score for the Naive Bayes model on train set: {f1_score(y_train, y_train_nb)}\")\n",
    "print(f\"F1 Score for the Naive Bayes model on test set: {f1_score(y_test, y_test_nb)}\\n\")\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_train_logreg = logreg.predict(X_train)\n",
    "y_test_logreg = logreg.predict(X_test)\n",
    "\n",
    "print(f\"F1 Score for the Logistic Regression model on train set: {f1_score(y_train, y_train_logreg)}\")\n",
    "print(f\"F1 Score for the Logistic Regression model on test set: {f1_score(y_test, y_test_logreg)}\\n\")\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "y_train_rfc = rfc.predict(X_train)\n",
    "y_test_rfc = rfc.predict(X_test)\n",
    "\n",
    "print(f\"F1 Score for the Random Forest model on train set: {f1_score(y_train, y_train_rfc)}\")\n",
    "print(f\"F1 Score for the Random Forest model on test set: {f1_score(y_test, y_test_rfc)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression and Random Forest seem to be the most promising so we'll stick to them from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': range(2, 11, 2),\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [10, 25, 50, 100]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Grid Search\n",
    "classifier = RandomForestClassifier()\n",
    "params = {\"n_estimators\": [10, 25, 50, 100], 'max_depth': range(2, 11, 2), 'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "gridsearch = GridSearchCV(classifier, param_grid = params, cv = 5, scoring='f1_micro', verbose=2)\n",
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters :  {'max_depth': 8, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters : \", gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for the Random Forest model on train set: 0.7643114164213282\n",
      "F1 Score for the Random Forest model on test set: 0.751913107874599\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth= 8, min_samples_split= 10, n_estimators= 100)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_train_rfc = rfc.predict(X_train)\n",
    "y_test_rfc = rfc.predict(X_test)\n",
    "\n",
    "print(f\"F1 Score for the Random Forest model on train set: {f1_score(y_train, y_train_rfc)}\")\n",
    "print(f\"F1 Score for the Random Forest model on test set: {f1_score(y_test, y_test_rfc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score is OK and there is no overfitting, let's try Logistic Regression with a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning:\n",
      "\n",
      "\n",
      "1800 fits failed out of a total of 4000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/Users/guillaumearp/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning:\n",
      "\n",
      "One or more of the test scores are non-finite: [       nan        nan 0.98532574        nan 0.98551315 0.98570994\n",
      " 0.98570994 0.98503057 0.98570994 0.98570994        nan        nan\n",
      "        nan        nan        nan 0.98627217 0.98627217        nan\n",
      " 0.98627217 0.98627217        nan        nan 0.98532574        nan\n",
      " 0.98551315 0.98570994 0.98570994 0.98503057 0.98570994 0.98570994\n",
      "        nan        nan        nan        nan        nan 0.98627217\n",
      " 0.98627217        nan 0.98627217 0.98627217        nan        nan\n",
      " 0.98532574        nan 0.98551315 0.98570994 0.98570994 0.98503057\n",
      " 0.98570994 0.98570994        nan        nan        nan        nan\n",
      "        nan 0.98627217 0.98627217        nan 0.98627217 0.98627217\n",
      "        nan        nan 0.98532574        nan 0.98551315 0.98570994\n",
      " 0.98570994 0.98503057 0.98570994 0.98570525        nan        nan\n",
      "        nan        nan        nan 0.98627217 0.98627217        nan\n",
      " 0.98627217 0.98627217        nan        nan 0.98628622        nan\n",
      " 0.98628622 0.98627217 0.98627217 0.98622531 0.98627217 0.98627217\n",
      "        nan        nan        nan        nan        nan 0.98627217\n",
      " 0.98627217        nan 0.98627217 0.98627217        nan        nan\n",
      " 0.98628622        nan 0.98628622 0.98627217 0.98627217 0.98622531\n",
      " 0.98627217 0.98627217        nan        nan        nan        nan\n",
      "        nan 0.98627217 0.98627217        nan 0.98627217 0.98627217\n",
      "        nan        nan 0.98628622        nan 0.98628622 0.98627217\n",
      " 0.98627217 0.98622531 0.98627217 0.98627217        nan        nan\n",
      "        nan        nan        nan 0.98627217 0.98627217        nan\n",
      " 0.98627217 0.98627217        nan        nan 0.98628622        nan\n",
      " 0.98628622 0.98627217 0.98627217 0.98622531 0.98627217 0.98627217\n",
      "        nan        nan        nan        nan        nan 0.98627217\n",
      " 0.98627217        nan 0.98627217 0.98627217        nan        nan\n",
      " 0.98628154        nan 0.98628154 0.98629559 0.98629559 0.98627217\n",
      " 0.98629559 0.98629559        nan        nan        nan        nan\n",
      "        nan 0.98627217 0.98627217        nan 0.98627217 0.98627217\n",
      "        nan        nan 0.98628154        nan 0.98628154 0.98629559\n",
      " 0.98629559 0.98627217 0.98629559 0.98629559        nan        nan\n",
      "        nan        nan        nan 0.98627217 0.98627217        nan\n",
      " 0.98627217 0.98627217        nan        nan 0.98628154        nan\n",
      " 0.98628154 0.98629559 0.98629559 0.98627217 0.98629559 0.98629559\n",
      "        nan        nan        nan        nan        nan 0.98627217\n",
      " 0.98627217        nan 0.98627685 0.98627217        nan        nan\n",
      " 0.98628154        nan 0.98628154 0.98629559 0.98629559 0.98627217\n",
      " 0.98629559 0.98629559        nan        nan        nan        nan\n",
      "        nan 0.98627217 0.98627217        nan 0.98627217 0.98627217\n",
      "        nan        nan 0.98628154        nan 0.98628154 0.98628154\n",
      " 0.98628154 0.9862628  0.98628154 0.98628154        nan        nan\n",
      "        nan        nan        nan 0.98627217 0.98627217        nan\n",
      " 0.98627217 0.98627217        nan        nan 0.98628154        nan\n",
      " 0.98628154 0.98628154 0.98628154 0.9862628  0.98628154 0.98628154\n",
      "        nan        nan        nan        nan        nan 0.98627217\n",
      " 0.98627217        nan 0.98627217 0.98627217        nan        nan\n",
      " 0.98628154        nan 0.98628154 0.98628154 0.98628154 0.9862628\n",
      " 0.98628154 0.98628154        nan        nan        nan        nan\n",
      "        nan 0.98627217 0.98627217        nan 0.98627217 0.98627217\n",
      "        nan        nan 0.98628154        nan 0.98628154 0.98628154\n",
      " 0.98628154 0.9862628  0.98628154 0.98628154        nan        nan\n",
      "        nan        nan        nan 0.98627217 0.98627217        nan\n",
      " 0.98627217 0.98627217        nan        nan 0.98628154        nan\n",
      " 0.98628154 0.98629091 0.98629091 0.98626748 0.98629091 0.98629091\n",
      "        nan        nan        nan        nan        nan 0.98627217\n",
      " 0.98627217        nan 0.98627217 0.98627217        nan        nan\n",
      " 0.98628154        nan 0.98628154 0.98629091 0.98629091 0.98626748\n",
      " 0.98629091 0.98629091        nan        nan        nan        nan\n",
      "        nan 0.98627217 0.98627217        nan 0.98627217 0.98627685\n",
      "        nan        nan 0.98628154        nan 0.98628154 0.98629091\n",
      " 0.98629091 0.98626748 0.98629091 0.98629091        nan        nan\n",
      "        nan        nan        nan 0.98627217 0.98627217        nan\n",
      " 0.98627217 0.98627217        nan        nan 0.98628154        nan\n",
      " 0.98628154 0.98629091 0.98629091 0.98626748 0.98629091 0.98629091\n",
      "        nan        nan        nan        nan        nan 0.98627217\n",
      " 0.98627217        nan 0.98627217 0.98627217        nan        nan\n",
      " 0.98628154        nan 0.98628154 0.98628622 0.98628622 0.98627685\n",
      " 0.98628622 0.98628622        nan        nan        nan        nan\n",
      "        nan 0.98627217 0.98627217        nan 0.98627217 0.98627217\n",
      "        nan        nan 0.98628154        nan 0.98628154 0.98628622\n",
      " 0.98628622 0.98627685 0.98628622 0.98628622        nan        nan\n",
      "        nan        nan        nan 0.98627217 0.98627217        nan\n",
      " 0.98627217 0.98627217        nan        nan 0.98628154        nan\n",
      " 0.98628154 0.98628622 0.98628622 0.98627685 0.98628622 0.98628622\n",
      "        nan        nan        nan        nan        nan 0.98627217\n",
      " 0.98627217        nan 0.98627217 0.98627217        nan        nan\n",
      " 0.98628154        nan 0.98628154 0.98628622 0.98628622 0.98627685\n",
      " 0.98628622 0.98628622        nan        nan        nan        nan\n",
      "        nan 0.98627217 0.98627217        nan 0.98627685 0.98627217\n",
      "        nan        nan 0.98627685        nan 0.98628154 0.98628154\n",
      " 0.98628154 0.98628622 0.98628622 0.98628154        nan        nan\n",
      "        nan        nan        nan 0.98627217 0.98627217        nan\n",
      " 0.98627217 0.98627217        nan        nan 0.98627685        nan\n",
      " 0.98628154 0.98628154 0.98628154 0.98628622 0.98628622 0.98628154\n",
      "        nan        nan        nan        nan        nan 0.98627217\n",
      " 0.98627217        nan 0.98627217 0.98627217        nan        nan\n",
      " 0.98627685        nan 0.98628154 0.98628154 0.98628154 0.98628622\n",
      " 0.98628154 0.98628154        nan        nan        nan        nan\n",
      "        nan 0.98627217 0.98627217        nan 0.98627685 0.98627217\n",
      "        nan        nan 0.98627685        nan 0.98628154 0.98628154\n",
      " 0.98628154 0.98628622 0.98628154 0.98628154        nan        nan\n",
      "        nan        nan        nan 0.98627217 0.98627217        nan\n",
      " 0.98627217 0.98627217        nan        nan 0.98627685        nan\n",
      " 0.98627685 0.98628154 0.98628154 0.98628154 0.98628154 0.98628154\n",
      "        nan        nan        nan        nan        nan 0.98627217\n",
      " 0.98627217        nan 0.98627217 0.98627217        nan        nan\n",
      " 0.98627685        nan 0.98627685 0.98628154 0.98628154 0.98628154\n",
      " 0.98628154 0.98628154        nan        nan        nan        nan\n",
      "        nan 0.98627217 0.98627217        nan 0.98627217 0.98627217\n",
      "        nan        nan 0.98627685        nan 0.98627685 0.98628154\n",
      " 0.98628154 0.98628154 0.98628154 0.98628154        nan        nan\n",
      "        nan        nan        nan 0.98627217 0.98627217        nan\n",
      " 0.98627217 0.98627217        nan        nan 0.98627685        nan\n",
      " 0.98627685 0.98628154 0.98628154 0.98628154 0.98628154 0.98628154\n",
      "        nan        nan        nan        nan        nan 0.98627217\n",
      " 0.98627217        nan 0.98627217 0.98627217        nan        nan\n",
      " 0.98627685        nan 0.98627685 0.98628154 0.98628154 0.98628154\n",
      " 0.98628154 0.98628154        nan        nan        nan        nan\n",
      "        nan 0.98627217 0.98627217        nan 0.98627217 0.98627217\n",
      "        nan        nan 0.98627685        nan 0.98627685 0.98628154\n",
      " 0.98628154 0.98628154 0.98628154 0.98628154        nan        nan\n",
      "        nan        nan        nan 0.98627217 0.98627217        nan\n",
      " 0.98627217 0.98627217        nan        nan 0.98627685        nan\n",
      " 0.98627685 0.98628154 0.98628154 0.98628154 0.98628154 0.98628154\n",
      "        nan        nan        nan        nan        nan 0.98627217\n",
      " 0.98627217        nan 0.98627217 0.98627217        nan        nan\n",
      " 0.98627685        nan 0.98627685 0.98628154 0.98628154 0.98628154\n",
      " 0.98628154 0.98628154        nan        nan        nan        nan\n",
      "        nan 0.98627217 0.98627217        nan 0.98627217 0.98627217\n",
      "        nan        nan 0.98627685        nan 0.98627685 0.98628154\n",
      " 0.98628154 0.98628622 0.98628154 0.98628154        nan        nan\n",
      "        nan        nan        nan 0.98627217 0.98627217        nan\n",
      " 0.98627685 0.98627217        nan        nan 0.98627685        nan\n",
      " 0.98627685 0.98628154 0.98628154 0.98628622 0.98628154 0.98628154\n",
      "        nan        nan        nan        nan        nan 0.98627217\n",
      " 0.98627217        nan 0.98627217 0.98627217        nan        nan\n",
      " 0.98627685        nan 0.98627685 0.98628154 0.98628154 0.98628622\n",
      " 0.98628154 0.98628154        nan        nan        nan        nan\n",
      "        nan 0.98627217 0.98627217        nan 0.98627217 0.98627217\n",
      "        nan        nan 0.98627685        nan 0.98627685 0.98628154\n",
      " 0.98628154 0.98628622 0.98628154 0.98628154        nan        nan\n",
      "        nan        nan        nan 0.98627217 0.98627217        nan\n",
      " 0.98627217 0.98627217]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([0.01      , 0.56444444, 1.11888889, 1.67333333, 2.22777778,\n",
       "       2.78222222, 3.33666667, 3.89111111, 4.44555556, 5.        ]),\n",
       "                         'max_iter': [100, 250, 500, 1000],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'solver': ['lbfgs', 'newton-cg', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Grid Search\n",
    "classifier = LogisticRegression()\n",
    "params = {'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'solver': ['lbfgs','newton-cg','liblinear','sag','saga'], 'C': np.linspace(0.01, 5, 10), 'max_iter': [100, 250, 500, 1000]}\n",
    "\n",
    "gridsearch = GridSearchCV(classifier, param_grid = params, cv = 5, scoring='f1_micro', verbose=2)\n",
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters :  {'C': 1.118888888888889, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters : \", gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for the Logistic Regression model on train set: 0.7640395275970113\n",
      "F1 Score for the Logistic Regression model on test set: 0.7619970916141542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty='l2', solver='lbfgs', C=1.12, max_iter=100)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_train_logreg = logreg.predict(X_train)\n",
    "y_test_logreg = logreg.predict(X_test)\n",
    "\n",
    "print(f\"F1 Score for the Logistic Regression model on train set: {f1_score(y_train, y_train_logreg)}\")\n",
    "print(f\"F1 Score for the Logistic Regression model on test set: {f1_score(y_test, y_test_logreg)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.974264\n",
       "1    0.025736\n",
       "dtype: float64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test_logreg).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.967742\n",
       "1    0.032258\n",
       "Name: converted, dtype: float64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('conversion_data_train.csv')\n",
    "df['converted'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for the XGBoost Classifier model on train set: 0.7768092762894843\n",
      "F1 Score for the XGBoost Classifier model on test set: 0.7603941360249941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=8, min_child_weight=10, n_estimators=100)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_train_xgb = xgb.predict(X_train)\n",
    "y_test_xgb = xgb.predict(X_test)\n",
    "\n",
    "print(f\"F1 Score for the XGBoost Classifier model on train set: {f1_score(y_train, y_train_xgb)}\")\n",
    "print(f\"F1 Score for the XGBoost Classifier model on test set: {f1_score(y_test, y_test_xgb)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 252 candidates, totalling 1260 fits\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=200; total time=  12.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=100; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=100; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=100; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=100; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=200; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=200; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=200; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=200; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=8, n_estimators=200; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=200; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=200; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=200; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=200; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=200; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=200; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=200; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=200; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=200; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=6, n_estimators=200; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=200; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=200; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=200; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=200; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.2, max_depth=8, n_estimators=200; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=200; total time=  22.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=200; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=200; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=200; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=8, n_estimators=200; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=100; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=100; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=100; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=100; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=100; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=200; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=200; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=200; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=200; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.4, max_depth=8, n_estimators=200; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=200; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=200; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=200; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=200; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.5, max_depth=8, n_estimators=200; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=200; total time=  18.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=100; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=100; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=100; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=100; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=100; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=200; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=200; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=200; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=200; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=8, n_estimators=200; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=200; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=200; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=200; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=200; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=6, n_estimators=200; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=200; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=200; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.1, max_depth=8, n_estimators=200; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=200; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=200; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=200; total time=  21.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=200; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, n_estimators=200; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=200; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=200; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=200; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=200; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=8, n_estimators=200; total time=  13.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=200; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=200; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=200; total time=  13.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=200; total time=  15.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.3, max_depth=8, n_estimators=200; total time=  17.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=100; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=100; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=100; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=100; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=100; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=200; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=200; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=200; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=200; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.4, max_depth=8, n_estimators=200; total time=  18.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=200; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=200; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=200; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=200; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.5, max_depth=8, n_estimators=200; total time=  10.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   6.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   6.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   8.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   8.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   8.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   8.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200; total time=   8.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=50; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   5.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200; total time=  12.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200; total time=  13.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200; total time=  12.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200; total time=  13.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200; total time=  12.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100; total time=   8.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100; total time=  13.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   9.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   7.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   7.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   7.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200; total time=   7.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=50; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=100; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=200; total time=  10.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=200; total time=  11.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=200; total time=  10.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=200; total time=  10.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=200; total time=  10.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200; total time=   7.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200; total time=   7.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200; total time=   7.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200; total time=   8.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=50; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   6.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   6.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200; total time=  11.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200; total time=  13.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200; total time=  13.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200; total time=  24.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200; total time= 1.1min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=50; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=2, n_estimators=200; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=50; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200; total time=   9.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200; total time=   9.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200; total time=  15.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200; total time=  17.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200; total time=   7.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=50; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   6.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=200; total time=  10.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=200; total time=  10.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=200; total time=  11.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=200; total time=   9.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=200; total time=  10.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=100; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=4, n_estimators=200; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=100; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   7.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   6.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=6, n_estimators=200; total time=   7.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=50; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=100; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=200; total time=   9.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=200; total time=   8.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=200; total time=   9.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=200; total time=   8.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.3, max_depth=8, n_estimators=200; total time=   8.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=50; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=100; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=4, n_estimators=200; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=50; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=100; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   9.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   8.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   9.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   9.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=6, n_estimators=200; total time=   8.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=50; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=100; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=100; total time=  10.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=100; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=100; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=100; total time=   6.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=200; total time=  12.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=200; total time=  12.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=200; total time=  11.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=200; total time=  10.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.4, max_depth=8, n_estimators=200; total time=   9.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=2, n_estimators=200; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=50; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=100; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=4, n_estimators=200; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=50; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=100; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   6.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   7.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   6.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   7.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=6, n_estimators=200; total time=   6.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=50; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=100; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=200; total time=  10.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=200; total time=   9.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=200; total time=   9.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=200; total time=  10.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.5, max_depth=8, n_estimators=200; total time=   9.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_ca...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.5, 0.75, 1.0],\n",
       "                         'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         'max_depth': range(2, 9, 2),\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             scoring='f1_micro', verbose=2)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = XGBClassifier()\n",
    "params = {\"n_estimators\": [50, 100, 200], 'max_depth': range(2, 9, 2), 'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5], 'colsample_bytree': [0.5, 0.75, 1.0]}\n",
    "\n",
    "gridsearch = GridSearchCV(classifier, param_grid = params, cv = 5, scoring='f1_micro', verbose=2)\n",
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters :  {'colsample_bytree': 0.5, 'learning_rate': 0.4, 'max_depth': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters : \", gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for the XGBoost Classifier model on train set: 0.7642524490123657\n",
      "F1 Score for the XGBoost Classifier model on test set: 0.7606382978723404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=100, colsample_bytree=0.5, max_depth=2, learning_rate=0.4)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_train_xgb = xgb.predict(X_train)\n",
    "y_test_xgb = xgb.predict(X_test)\n",
    "\n",
    "print(f\"F1 Score for the XGBoost Classifier model on train set: {f1_score(y_train, y_train_xgb)}\")\n",
    "print(f\"F1 Score for the XGBoost Classifier model on test set: {f1_score(y_test, y_test_xgb)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tVVDRABv91O"
   },
   "source": [
    "# Train best classifier on all data and use it to make predictions on X_without_labels\n",
    "**Before making predictions on the file conversion_data_test.csv, let's train our model on ALL the data that was in conversion_data_train.csv. Sometimes, this allows to make tiny improvements in the score because we're using more examples to train the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "M14RHUadzE2p",
    "outputId": "abcfcfec-9461-4579-adbd-f23270f984eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.5,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.4, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate our train and test set to train your best classifier on all data with labels\n",
    "X_full = np.append(X_train,X_test,axis=0)\n",
    "y_full = np.append(y_train,y_test)\n",
    "\n",
    "logreg = LogisticRegression(penalty='l2', solver='lbfgs', C=1.12, max_iter=100)\n",
    "logreg.fit(X_full,y_full)\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=100, colsample_bytree=0.5, max_depth=2, learning_rate=0.4)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284580, 8)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "Tr4CEaPzzbP-",
    "outputId": "f0d1c8ed-be4b-4974-d7b9-f23a49344d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction set (without labels) : (31620, 5)\n",
      "[[-0.30935647 -1.47847297  3.3266299   0.          1.          0.\n",
      "   0.          1.        ]\n",
      " [-1.03417936  0.67637354  0.03732609  0.          1.          0.\n",
      "   1.          0.        ]\n",
      " [ 0.17385878  0.67637354 -1.15878439  0.          0.          0.\n",
      "   0.          1.        ]\n",
      " [ 0.17385878  0.67637354  0.33635371  0.          0.          1.\n",
      "   0.          0.        ]\n",
      " [-0.67176792 -1.47847297 -0.56072915  0.          0.          0.\n",
      "   0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Read data without labels\n",
    "data_without_labels = pd.read_csv('conversion_data_test.csv')\n",
    "print('Prediction set (without labels) :', data_without_labels.shape)\n",
    "\n",
    "# Warning : check consistency of features_list (must be the same than the features \n",
    "# used by your best classifier)\n",
    "\n",
    "data_without_labels = data_without_labels.loc[:, cols]\n",
    "data_without_labels = data_without_labels.values\n",
    "X_without_labels = preprocessor.transform(data_without_labels)\n",
    "\n",
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "\n",
    "\n",
    "print(X_without_labels[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "LoUISfsT0HMR",
    "outputId": "e42dc389-5e77-4e13-ccbc-1fef4aa2c0ca"
   },
   "outputs": [],
   "source": [
    "# # WARNING : PUT HERE THE SAME PREPROCESSING AS FOR YOUR TEST SET\n",
    "# # CHECK YOU ARE USING X_without_labels\n",
    "# print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "# X_without_labels = preprocessor.transform(X_without_labels)\n",
    "# print(\"...Done\")\n",
    "# print(X_without_labels[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DuWSEHuwEQJ"
   },
   "outputs": [],
   "source": [
    "# Make predictions and dump to file\n",
    "# WARNING : MAKE SURE THE FILE IS A CSV WITH ONE COLUMN NAMED 'converted' AND NO INDEX !\n",
    "# WARNING : FILE NAME MUST HAVE FORMAT 'conversion_data_test_predictions_[name].csv'\n",
    "# where [name] is the name of your team/model separated by a '-'\n",
    "# For example : [name] = AURELIE-model1\n",
    "\n",
    "\n",
    "results = {\n",
    "    'converted': logreg.predict(X_without_labels)\n",
    "}\n",
    "\n",
    "Y_predictions = pd.DataFrame(columns=['converted'],data=results)\n",
    "Y_predictions.to_csv('conversion_data_test_predictions_Guillaume-LR.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.974004\n",
       "1    0.025996\n",
       "dtype: float64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_full_lr = logreg.predict(X_without_labels)\n",
    "pd.Series(y_test_full_lr).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.973972\n",
      "1    0.026028\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_test_full_xgb = xgb.predict(X_without_labels)\n",
    "print(pd.Series(y_test_full_xgb).value_counts(normalize=True))\n",
    "\n",
    "results = {\n",
    "    'converted': xgb.predict(X_without_labels)\n",
    "}\n",
    "\n",
    "Y_predictions = pd.DataFrame(columns=['converted'],data=results)\n",
    "Y_predictions.to_csv('conversion_data_test_predictions_Guillaume-XGB.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the coefficients and interpreting the result\n",
    "**In this template, we just trained a model with only one feature (total_pages_visited), so there's no analysis to be done about the feature importance ü§î**\n",
    "\n",
    "**Once you've included more features in your model, please take some time to analyze the model's parameters and try to find some lever for action to improve the newsletter's conversion rate üòéüòé**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_encoded = preprocessor.transformers_[1][1].named_steps['encoder'].get_feature_names_out().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'new_user',\n",
       " 'total_pages_visited',\n",
       " 'x0_Germany',\n",
       " 'x0_UK',\n",
       " 'x0_US',\n",
       " 'x1_Direct',\n",
       " 'x1_Seo']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('conversion_data_train.csv')\n",
    "columns = df.columns.tolist()\n",
    "columns.pop(0)\n",
    "columns.pop(2)\n",
    "columns = columns[:-1]\n",
    "columns += features_encoded\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x0_Germany</th>\n",
       "      <td>0.975096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x0_UK</th>\n",
       "      <td>0.970426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x0_US</th>\n",
       "      <td>0.957487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_pages_visited</th>\n",
       "      <td>0.926931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1_Seo</th>\n",
       "      <td>0.496350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1_Direct</th>\n",
       "      <td>0.450101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.354667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_user</th>\n",
       "      <td>0.312322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         coef\n",
       "x0_Germany           0.975096\n",
       "x0_UK                0.970426\n",
       "x0_US                0.957487\n",
       "total_pages_visited  0.926931\n",
       "x1_Seo               0.496350\n",
       "x1_Direct            0.450101\n",
       "age                  0.354667\n",
       "new_user             0.312322"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_logreg = logreg.coef_[0]\n",
    "coef_logreg = pd.DataFrame([np.exp(x)/(1 + np.exp(x)) for x in logreg.coef_[0]], columns, columns=['coef']).sort_values(by='coef', ascending=False)\n",
    "coef_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`country` and `total_pages_visited` seem to be the most important features, followed by `source` with half the coefficient, and finally `age` and `new_user`."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Projets_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
